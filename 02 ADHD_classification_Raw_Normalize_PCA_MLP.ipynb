{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-DLDBC8d7Atc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed4bfb8-5cab-44bd-f40c-dfb36ef9cc0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zslnKsESdkci"
      },
      "outputs": [],
      "source": [
        "# Enter your path here which contains directories named ADHD_part1 and so on and so forth, the /content is path on my setup\n",
        "PATH = \"/content/drive/MyDrive/Archive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rffmIw3XfJy9"
      },
      "outputs": [],
      "source": [
        "ADHD_directories = [\"ADHD_part1\",\"ADHD_part2\"]\n",
        "NonADHD_directories = [\"Control_part1\",\"Control_part2\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EHQ-FSlpRMMR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import scipy.io\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNAr-AmxptX_"
      },
      "source": [
        "Data Loading Procedure, assigning labels and preapring a tensorflow dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8RzRzTQfQFL4"
      },
      "outputs": [],
      "source": [
        "def normalize(matrix):\n",
        "  means = np.mean(matrix,axis=0)\n",
        "  var = np.var(matrix,axis=0)\n",
        "  for row in range(matrix.shape[0]):\n",
        "    matrix[row] = (matrix[row]-means)/var\n",
        "  return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cySOcoIPTVua"
      },
      "outputs": [],
      "source": [
        "#this takes 100 most important vectors according to pca, this value could be increased but corresponding change should be made in tf.keras.layer.Input\n",
        "def pca_for_feature_extraction(matrix):\n",
        "  eigen_values, eigen_vectors = tf.linalg.eigh(tf.tensordot(tf.transpose(matrix), matrix, axes=1))\n",
        "  m = tf.tensordot(tf.transpose(eigen_vectors), tf.transpose(matrix), axes=1)\n",
        "  m = np.transpose(m)\n",
        "  m = m[:,:10]\n",
        "  an_empty_array= np.zeros(shape = (50000,10))\n",
        "  for i in range(m.shape[0]):\n",
        "    for j in range(m.shape[1]):\n",
        "      an_empty_array[i][j] = m[i][j]\n",
        "  return an_empty_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7z-3NfO2fqjU"
      },
      "outputs": [],
      "source": [
        "\n",
        "labels = []\n",
        "eeg_data = []\n",
        "#Iterating all ADHD containing file\n",
        "for directory in ADHD_directories:\n",
        "  for mat_file in os.listdir(os.path.join(PATH,directory)):\n",
        "    #loading the file\n",
        "    loaded_file = scipy.io.loadmat(os.path.join(PATH,directory,mat_file))\n",
        "    #getting data from the loaded file, mat_file[:-4] gives name of file without .mat\n",
        "    per_person_data = loaded_file[mat_file[:-4]]\n",
        "    per_person_data = normalize(np.array(per_person_data,dtype=float))\n",
        "    feature_extracted_per_person_data = pca_for_feature_extraction(per_person_data)\n",
        "    eeg_data.append(feature_extracted_per_person_data)\n",
        "    #adding label 1 corresponding to adhd\n",
        "    labels.append(1)\n",
        "for directory in NonADHD_directories:\n",
        "  for mat_file in os.listdir(os.path.join(PATH,directory)):\n",
        "    loaded_file = scipy.io.loadmat(os.path.join(PATH,directory,mat_file))\n",
        "    per_person_data = loaded_file[mat_file[:-4]]\n",
        "    per_person_data = normalize(np.array(per_person_data,dtype=float))\n",
        "    feature_extracted_per_person_data = pca_for_feature_extraction(per_person_data)\n",
        "    eeg_data.append(feature_extracted_per_person_data)\n",
        "    labels.append(0)\n",
        "# since all files do not have one consistent data size(can be seen by print(per_person_data.shape) \n",
        "#before appending to eeg_data) used ragged contant\n",
        "tensors_data = tf.data.Dataset.from_tensor_slices(np.array(eeg_data))\n",
        "tensors_labels = tf.data.Dataset.from_tensor_slices(labels)\n",
        "# adding two datasets together so that we have data with classes/labels\n",
        "dataset = tf.data.Dataset.zip((tensors_data,tensors_labels))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU_DqgICQeTi",
        "outputId": "0ce73fc8-4e6f-4a7f-95b5-c8df2dd199ad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "121"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "df = tfds.as_dataframe(tensors_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "BdYyNTqwNCIM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rqr5CWokN2AS",
        "outputId": "b2a347a3-ec34-47ce-9e21-d6c346b8c1b3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "121"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M9FQpsiMlhN",
        "outputId": "67de8c43-2710-451a-c51c-51f137247679"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ZipDataset element_spec=(TensorSpec(shape=(50000, 10), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QT3FxLL2zDkv"
      },
      "outputs": [],
      "source": [
        "def get_dataset_partitions_tf(ds, ds_size, train_split=0.7, val_split=0.15, test_split=0.15, shuffle=True, shuffle_size=10000):\n",
        "    assert (train_split + test_split + val_split) == 1\n",
        "    if shuffle:\n",
        "        # Specify seed to always have the same split distribution between runs\n",
        "        ds = ds.shuffle(shuffle_size, seed=12)\n",
        "    \n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "    \n",
        "    train_ds = ds.take(train_size)    \n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "  \n",
        "    return train_ds, val_ds, test_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RdBGf65pzEyc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be225a62-864d-46ad-f4cb-03b90d4d0847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of people involved in dataset  121\n"
          ]
        }
      ],
      "source": [
        "train_ds,val_ds,test_ds = get_dataset_partitions_tf(dataset,len(dataset))\n",
        "print(\"Total number of people involved in dataset \",len(dataset))\n",
        "train_ds = train_ds.batch(32)\n",
        "val_ds = val_ds.batch(32)\n",
        "test_ds = test_ds.batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0pFyUf7Gppzj"
      },
      "outputs": [],
      "source": [
        "#tf.keras.layers.Input(shape=(100,19)) has 100 in it because we have taken 50 most important features from pca   \n",
        "def create_model():\n",
        "  keras_model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Input(shape=(50000,10)),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(1000),\n",
        "      tf.keras.layers.Activation(tf.nn.relu),\n",
        "      tf.keras.layers.Dense(500),\n",
        "      tf.keras.layers.Activation(tf.nn.relu),\n",
        "      tf.keras.layers.Dense(100),\n",
        "      tf.keras.layers.Activation(tf.nn.relu),\n",
        "      tf.keras.layers.Dense(50),\n",
        "      tf.keras.layers.Activation(tf.nn.relu),\n",
        "      tf.keras.layers.Dense(10),\n",
        "      tf.keras.layers.Activation(tf.nn.relu),\n",
        "      tf.keras.layers.Dense(2),\n",
        "      tf.keras.layers.Activation(tf.nn.softmax),\n",
        "])\n",
        "  return keras_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IUqcRLFM4Q8W"
      },
      "outputs": [],
      "source": [
        "model = create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Uabafj-A-0Ue"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "R83r1WoPaK6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b883f8da-aacf-4902-c6b4-4ff8fa6be38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 500000)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              500001000 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 500)               500500    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 500)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               50100     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 100)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 50)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                510       \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 22        \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 500,557,182\n",
            "Trainable params: 500,557,182\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model.fit takes up to one hour to run 150 epochs."
      ],
      "metadata": {
        "id": "tXSiJV6jj6y_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlph7UoZ_kqf",
        "outputId": "51928260-813c-45b5-898f-8e0f545dc720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "3/3 [==============================] - 18s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 2/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 3/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 4/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 5/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 6/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 7/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 8/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 9/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 10/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 11/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 12/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 13/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 14/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 15/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 16/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 17/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 18/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 19/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 20/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 21/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 22/150\n",
            "3/3 [==============================] - 14s 5s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 23/150\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 24/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 25/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 26/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 27/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5060 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 28/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 29/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 30/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 31/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 32/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 33/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 34/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 35/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 36/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 37/150\n",
            "3/3 [==============================] - 18s 7s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 38/150\n",
            "3/3 [==============================] - 18s 7s/step - loss: 0.6931 - binary_accuracy: 0.5060 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 39/150\n",
            "3/3 [==============================] - 13s 5s/step - loss: 0.6931 - binary_accuracy: 0.5060 - val_loss: 0.6931 - val_binary_accuracy: 0.5278\n",
            "Epoch 40/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 41/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 42/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 43/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 44/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 45/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 46/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 47/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 48/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 49/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 50/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5119 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 51/150\n",
            "3/3 [==============================] - 13s 5s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 52/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 53/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 54/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 55/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 56/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 57/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.4722\n",
            "Epoch 58/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 59/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 60/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 61/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5060 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 62/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 63/150\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 64/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 65/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 66/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 67/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 68/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 69/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 70/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5060 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 71/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 72/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5060 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 73/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 74/150\n",
            "3/3 [==============================] - 16s 6s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 75/150\n",
            "3/3 [==============================] - 16s 5s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 76/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 77/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 78/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 79/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 80/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5060 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 81/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5060 - val_loss: 0.6931 - val_binary_accuracy: 0.4722\n",
            "Epoch 82/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 83/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5119 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 84/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 85/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 86/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 87/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 88/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 89/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 90/150\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.6931 - binary_accuracy: 0.5060 - val_loss: 0.6931 - val_binary_accuracy: 0.4722\n",
            "Epoch 91/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5060 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 92/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 93/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 94/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 95/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5278\n",
            "Epoch 96/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 97/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 98/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 99/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 100/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 101/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 102/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 103/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 104/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 105/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 106/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 107/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 108/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 109/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 110/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 111/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 112/150\n",
            "3/3 [==============================] - 13s 5s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 113/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 114/150\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 115/150\n",
            "3/3 [==============================] - 14s 5s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 116/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 117/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 118/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 119/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 120/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5060 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 121/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5278\n",
            "Epoch 122/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5278\n",
            "Epoch 123/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5278\n",
            "Epoch 124/150\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 125/150\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.6931 - binary_accuracy: 0.5060 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 126/150\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.6931 - binary_accuracy: 0.5060 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 127/150\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 128/150\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 129/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 130/150\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 131/150\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 132/150\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 133/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 134/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 135/150\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 136/150\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 137/150\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.6931 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 138/150\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 139/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.4722\n",
            "Epoch 140/150\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 141/150\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 142/150\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 143/150\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 144/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 145/150\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.6931 - binary_accuracy: 0.5060 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 146/150\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 147/150\n",
            "3/3 [==============================] - 11s 3s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 148/150\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 149/150\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
            "Epoch 150/150\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "history = model.fit(\n",
        "    train_ds,    \n",
        "    batch_size=32,\n",
        "    epochs=150,\n",
        "    shuffle=True,\n",
        "    validation_data = val_ds,verbose='auto'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CUEUQqg5w0I8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e89870-b687-4057-e464-a281e113056f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "[[0.5000009  0.49999908]\n",
            " [0.5000031  0.49999696]\n",
            " [0.50000405 0.499996  ]\n",
            " [0.49999794 0.5000021 ]\n",
            " [0.4999987  0.5000013 ]\n",
            " [0.5000029  0.49999714]\n",
            " [0.49999765 0.5000024 ]\n",
            " [0.5000017  0.49999824]\n",
            " [0.5000033  0.49999675]\n",
            " [0.50000644 0.49999353]\n",
            " [0.5000015  0.49999848]\n",
            " [0.5000026  0.49999735]\n",
            " [0.49999973 0.5000003 ]\n",
            " [0.5000047  0.4999953 ]\n",
            " [0.5000036  0.4999964 ]\n",
            " [0.5000034  0.49999666]\n",
            " [0.50000286 0.4999972 ]\n",
            " [0.5000015  0.49999857]\n",
            " [0.5000025  0.49999747]]\n"
          ]
        }
      ],
      "source": [
        "print(model.predict(test_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "oskMoALhUzJp"
      },
      "outputs": [],
      "source": [
        "def print_accuracy(ds):\n",
        "  predictions = model.predict(ds)\n",
        "  predicted_labels = np.argmax(predictions, axis=1)\n",
        "  true_values = np.concatenate([y for x, y in ds], axis=0)\n",
        "  count = 0\n",
        "  for i in range(len(predicted_labels)):\n",
        "    if predicted_labels[i] == true_values[i]:\n",
        "      count = count + 1\n",
        "  print(\"The accuracy for given dataset is: \", count/len(predicted_labels)*100)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ibu-DphFUvKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2acdc796-2250-4adc-f5a5-2cab4a9cee73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 888ms/step\n",
            "The accuracy for given dataset is:  63.1578947368421\n"
          ]
        }
      ],
      "source": [
        "print_accuracy(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "EUJGsr5bY_-z"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "-kg3GesBjha7",
        "outputId": "dad72b79-8f2c-4d4b-e840-7c77513a6659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 925ms/step\n",
            "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 1 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 540x540 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "predictions = model.predict(test_ds)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "print(predicted_labels)\n",
        "true_values = np.concatenate([y for x, y in test_ds], axis=0)\n",
        "print(true_values)\n",
        "cm =confusion_matrix(true_values,predicted_labels,labels=[0, 1])\n",
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(cm, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(x=j, y=i,s=cm[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WnNTsFVy8Cb9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}